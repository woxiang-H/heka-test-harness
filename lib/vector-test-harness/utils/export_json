#!/usr/bin/env ruby

# This script exports the passed results into a .json file
#
# We use Ruby since we have to mangle with a complex data structure.
# Trying to print this table using bash utilities such as jq was
# painful.

require 'json'

require_relative "athena"
require_relative "util"

results_json = ARGV[0]
file_name = ARGV[1]

if results_json.nil?
  raise "You must pass the query results JSON as the first argument"
end

def build_measurements(rows)
  rows.
    flat_map do |row|
      extract_metrics([row]).
        select { |metric_slug| row.fetch(metric_slug) }.
        collect do |metric_slug|
          meta = fetch_metric_meta!(metric_slug)
          aggregate = meta.fetch(:aggregate)
          subject = row.fetch("subject")
          test = row.fetch("name")
          unit = meta.fetch(:unit)
          value = row.fetch(metric_slug)
          version = row.fetch("version")
          human_value = unit == "bytes" ? filesize(value) : value.round(2).to_s

          meta.merge(
            __type: "measurement",
            human_value: human_value,
            metric: metric_slug,
            subject: subject,
            test: test,
            value: value,
            version: version
          )
        end
    end
end

def build_metrics(rows)
  extract_metrics(rows).
    collect do |metric_slug|
      metric_rows = rows.select { |row| !row.fetch(metric_slug).nil? }
      subjects = extract_subjects(metric_rows)
      tests = extract_tests(metric_rows)

      fetch_metric_meta!(metric_slug).merge(
        __type: "metric",
        slug: metric_slug,
        subjects: subjects,
        tests: tests
      )
    end.
    sort_by { |metric| metric.fetch(:name) }
end

def build_subjects(rows)
  rows.
    group_by { |row| row.fetch("subject") }.
    collect do |subject_slug, subject_rows|
      metrics = extract_metrics(subject_rows)
      tests = extract_tests(subject_rows)
      versions = extract_versions(subject_rows)

      fetch_subject_meta!(subject_slug).merge(
        __type: "subject",
        metrics: metrics,
        slug: subject_slug,
        tests: tests,
        versions: versions
      )
    end.
    sort_by do |subject|
      name = subject.fetch(:name)

      if name.downcase == "vector"
        "AAAAAA"
      else
        name
      end
    end
end

def build_tests(rows)
  rows.
    group_by { |row| row.fetch("name") }.
    collect do |test_slug, test_rows|
      metrics = extract_metrics(test_rows)
      subjects = extract_subjects(test_rows)

      fetch_test_meta!(test_slug).merge(
        __type: "test",
        metrics: metrics,
        slug: test_slug,
        subjects: subjects
      )
    end.
    sort_by { |test| test.fetch(:name) }
end

def extract_metrics(rows)
  rows.
    flat_map do |row|
      row.keys.select { |key| is_metric?(key) }
    end.
    uniq.
    sort
end

def extract_subjects(rows)
  rows.
    collect { |row| row.fetch("subject") }.
    uniq.
    sort
end

def extract_tests(rows)
  rows.
    collect { |row| row.fetch("name") }.
    uniq.
    sort
end

def extract_versions(rows)
  rows.
    collect { |row| row.fetch("version") }.
    uniq.
    sort.
    collect do |version_string|
      version = Gem::Version.new(version_string)

      {
        __type: "version",
        major: version.segments[0],
        minor: version.segments[1],
        name: version.to_s,
        patch: version.segments[2],
        prerelease: version.prerelease?,
        slug: version_string
      }
    end
end

def transform_to_data!(rows)
  rows =
    rows.collect do |row|
      name = row.fetch("name")
      throughput_avg = (name.include?("file") ? row.fetch("disk_read_avg") : row.fetch("net_recv_avg")).clone
      row["throughput_avg"] = throughput_avg
      row
    end

  tests = build_tests(rows)
  subjects = build_subjects(rows)
  measurements = build_measurements(rows)
  metrics = build_metrics(rows)

  {
    tests: tests,
    subjects: subjects,
    measurements: measurements,
    metrics: metrics
  }
end

results = JSON.parse(results_json)
result_set = results.fetch("ResultSet")
rows = result_set.fetch("Rows")
result_set_metadata = result_set.fetch("ResultSetMetadata")
hashes = transform_to_hashes!(rows, result_set_metadata)
data = transform_to_data!(hashes)
data = {performance_tests: data}
data = JSON.pretty_generate(data)

File.open(file_name, "w") do |f|
  f.write(data)
end
